{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args['country'] = 'Croatia'\n",
    "args['vision_credential'] = '/home/connect/prashant/Finland/mysecondvisionproject-4e1c5d1beb85.json'\n",
    "args['stage_options_file'] = \"statuses.xlsx\"\n",
    "args['similarity_threshold'] = 0.7\n",
    "args['industry_options_file'] = 'industries.xlsx'\n",
    "args['companies_file'] = 'companies.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/connect/.local/lib/python3.5/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "How to use it:\n",
    "\n",
    "python3 finland_ocr.py --images_path images/ --vision_credential vision_api.json --companies_excel_file Finland_companies.xlsx\n",
    "\n",
    "Assuming all images with PNG extension\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import io\n",
    "from google.cloud import vision\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import string\n",
    "from fuzzywuzzy import process\n",
    "import glob\n",
    "import pickle\n",
    "import simplediff\n",
    "\n",
    "def simplediff_score(raw, known):\n",
    "    diff_result = simplediff.diff(known, raw)\n",
    "    same = [len (t[1]) for t in diff_result if t[0] == \"=\"]\n",
    "    deletions = [len (t[1]) for t in diff_result if t[0] == \"-\"]\n",
    "    additions = [len (t[1]) for t in diff_result if t[0] == \"+\"]\n",
    "    n = 2*sum(same) - (sum(additions) + sum(deletions))/2\n",
    "    return n/(len(known)+len(raw))\n",
    "\n",
    "def partial_match(word , possibilities, cut_off=0.5):\n",
    "    if cut_off=='auto':\n",
    "        if len(word)>6:\n",
    "            cut_off = 1-(3/len(word))\n",
    "        elif len(word)>2:\n",
    "            cut_off = 1-(2/len(word))\n",
    "        else:\n",
    "            cut_off=0.5\n",
    "    max_score = 0\n",
    "#     possibilities = [each.lower() for each in possibilities ]\n",
    "    match = word\n",
    "    for each in possibilities:\n",
    "        score = simplediff_score(word,each)\n",
    "        if score>max_score:\n",
    "            max_score = score\n",
    "            match = each\n",
    "    if max_score>=cut_off:\n",
    "        return match,max_score\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_bin_image(image,th=127, inv=False):\n",
    "    '''Takes an image and returns its binary image'''\n",
    "    try:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    except:\n",
    "        pass\n",
    "    if inv:\n",
    "        _, bin_image = cv2.threshold(image, th, 255, cv2.THRESH_BINARY_INV)#|cv2.THRESH_OTSU)\n",
    "    else:\n",
    "        _, bin_image = cv2.threshold(image, th, 255, cv2.THRESH_BINARY)#|cv2.THRESH_OTSU)\n",
    "    return bin_image\n",
    "\n",
    "\n",
    "def white_percentage(bin_image, mode):\n",
    "    '''Takes a binary image i.e. {0,255} pixels values and returns percentage of white pixels across columns or rows as specified in mode parameter.'''\n",
    "\n",
    "    bin_image = bin_image.astype('int64')/255\n",
    "    h,w = bin_image.shape\n",
    "\n",
    "    if mode == 'horizontal':\n",
    "        srow = bin_image.sum(axis=1)\n",
    "        return srow/w*100\n",
    "    \n",
    "        p=10\n",
    "        parts = np.round(np.linspace(0,w,p+1))\n",
    "\n",
    "        part_white_percentage = []\n",
    "        \n",
    "        for i in range(p):\n",
    "            part_bin_image = bin_image[:,int(parts[i]):int(parts[i+1])]\n",
    "            _, part_w = part_bin_image.shape\n",
    "            part_srow = part_bin_image.sum(axis=1)\n",
    "            part_white_percentage.append(part_srow/part_w*100)\n",
    "\n",
    "        part_white_percentage = np.array(part_white_percentage).T\n",
    "\n",
    "        num_text_part = np.count_nonzero(part_white_percentage, axis=1)\n",
    "        num_text_part = num_text_part.clip(1)\n",
    "        return part_white_percentage.sum(axis=1)/num_text_part\n",
    "\n",
    "\n",
    "    elif mode == 'vertical':\n",
    "        scol = bin_image.sum(axis=0)\n",
    "        return (scol/h)*100\n",
    "\n",
    "    else:\n",
    "        print('Error: mode argument is missing')\n",
    "        return -1\n",
    "\n",
    "def get_band_lines(img_lines, min_band_sep=1, ignore_rate=0, ignore_rate_step=0.1, which='mid'):\n",
    "    '''\n",
    "    Returns 'which' line number of continous lines as defined by min_band_sep parameter.\n",
    "    Takes a list of tuples as [ (line_number, percentage_value), ...] and returns a list of tuples as [ (line_number, threshold_category), ...].\n",
    "    '''\n",
    "\n",
    "    cont_list= []\n",
    "    res_list = []\n",
    "\n",
    "    ###min_th = np.array(img_lines).min(axis=0)[1]\n",
    "\n",
    "    for line in img_lines:        \n",
    "            if len(cont_list)==0:\n",
    "                 cont_list.append(line)        \n",
    "            else:\n",
    "                if line[0]-cont_list[-1][0]<=min_band_sep:  ##cont_list[-1][0] to cont_list[0][0] to pick a band of max line height\n",
    "                    cont_list.append(line)\n",
    "                else:\n",
    "                    for th in np.arange(0, ignore_rate+ignore_rate_step, ignore_rate_step):\n",
    "                        th = round(th,1)\n",
    "                        line_list = [i[0] for i in cont_list if i[1] <= th]\n",
    "                        if line_list:\n",
    "                            res = line_list[0] if which=='first' else (line_list[-1] if which=='last' else line_list[math.floor((len(line_list))/2)])\n",
    "                            res_list.append((res,th))\n",
    "                            cont_list=[]\n",
    "                            cont_list.append(line)\n",
    "                            break\n",
    "            \n",
    "    for th in np.arange(0, ignore_rate+ignore_rate_step, ignore_rate_step):\n",
    "        th = round(th,1)\n",
    "        line_list = [i[0] for i in cont_list if i[1] <= th]\n",
    "        if line_list:\n",
    "            res = line_list[0] if which=='first' else (line_list[-1] if which=='last' else line_list[math.floor((len(line_list))/2)])\n",
    "            res_list.append((res,th))\n",
    "            break\n",
    "            \n",
    "    return res_list\n",
    "\n",
    "def google_hit(img_file, auth_key, api_type):\n",
    "\t'''Fetches the response from the google cloud API'''\n",
    "\n",
    "\tos.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = auth_key\n",
    "\tclient = vision.ImageAnnotatorClient()\n",
    "\n",
    "\twith io.open(img_file, 'rb') as image_file:\n",
    "\t\tcontent = image_file.read()\n",
    "\n",
    "\t\timage = vision.types.Image(content=content)\n",
    "\t# response = client.document_text_detection(image=image, image_context={\"language_hints\": [\"en\"]})\n",
    "\tif api_type=='document_text_detection':\n",
    "\t\tresponse = client.document_text_detection(image=image,image_context={\"language_hints\": [\"en\"]})\n",
    "\telif api_type=='text_detection':\n",
    "\t\tresponse = client.text_detection(image=image,image_context={\"language_hints\": [\"en\"]})\n",
    "\telse:\n",
    "\t\treturn 'Please mention the valid api_type'\n",
    "\tdocument = response.full_text_annotation\n",
    "\n",
    "\treturn document\n",
    "\n",
    "  \n",
    "def find_word_location(document,word_to_find):\n",
    "    word_list = []\n",
    "    for page in document.pages:\n",
    "        for block in page.blocks:\n",
    "            for paragraph in block.paragraphs:\n",
    "                for word in paragraph.words:\n",
    "                    assembled_word=assemble_word(word)\n",
    "                    if(assembled_word.lower()==word_to_find.lower()):\n",
    "                        word_list.append(word.bounding_box.vertices) \n",
    "    return word_list\n",
    "\n",
    "def assemble_word(word):\n",
    "    assembled_word = \"\"\n",
    "    for symbol in word.symbols:\n",
    "        assembled_word += symbol.text\n",
    "    return assembled_word\n",
    "\n",
    "\n",
    "def text_within(document,bbox):\n",
    "    '''finds out the text within a set of co-ordinates'''\n",
    "    x1,y1,x2,y2 = bbox\n",
    "   \n",
    "    symbols = []\n",
    "    for page in document.pages:\n",
    "        for block in page.blocks:\n",
    "            for paragraph in block.paragraphs:\n",
    "                for word in paragraph.words:\n",
    "                    for symbol in word.symbols:\n",
    "                        min_x=min(symbol.bounding_box.vertices[0].x,symbol.bounding_box.vertices[1].x,symbol.bounding_box.vertices[2].x,symbol.bounding_box.vertices[3].x)\n",
    "                        max_x=max(symbol.bounding_box.vertices[0].x,symbol.bounding_box.vertices[1].x,symbol.bounding_box.vertices[2].x,symbol.bounding_box.vertices[3].x)\n",
    "                        min_y=min(symbol.bounding_box.vertices[0].y,symbol.bounding_box.vertices[1].y,symbol.bounding_box.vertices[2].y,symbol.bounding_box.vertices[3].y)\n",
    "                        max_y=max(symbol.bounding_box.vertices[0].y,symbol.bounding_box.vertices[1].y,symbol.bounding_box.vertices[2].y,symbol.bounding_box.vertices[3].y)\n",
    "                        if(min_x >= x1 and max_x <= x2 and min_y >= y1 and max_y <= y2):\n",
    "                            symbols.append([symbol,min_x,min_y,max_x,max_y])\n",
    "    lines = ''                      \n",
    "    if len(symbols)>0:\n",
    "        df = pd.DataFrame(symbols)\n",
    "\n",
    "        df = df.sort_values([2,1])\n",
    "        df[2]=df[2].astype(int)\n",
    "        y_list = sorted( df[2].unique())\n",
    "        old_y = -y_list[0]\n",
    "        tol = 10\n",
    "        for y in y_list:\n",
    "            text=\"\"\n",
    "            if old_y+tol< y :\n",
    "                df_ = df[(df[2]>=y)&(df[2]<=y+tol)]\n",
    "                df_ = df_.sort_values(1)\n",
    "                old_y =y\n",
    "\n",
    "                for symbol in df_[0]:\n",
    "                    text+=symbol.text\n",
    "                    if(symbol.property.detected_break.type==1 or symbol.property.detected_break.type==3):\n",
    "                        text+=' '\n",
    "                    if(symbol.property.detected_break.type==2):\n",
    "                        text+='\\t'\n",
    "                    if(symbol.property.detected_break.type==5):\n",
    "                        text+='\\n'\n",
    "                lines = lines+text#.lower()\n",
    "    return lines.strip()\n",
    "\n",
    "\n",
    "def convert_to_int(s):\n",
    "\ttry:\n",
    "\t    text_string = s.translate(str.maketrans('', '',string.punctuation.replace('.','').replace(',','')))      \n",
    "\t    d={'D':'0','o':'0','O':'0','i':'1','I':'1','J':'1','l':'1','L':'1','!':'1','r':'1','s':'5','S':'5','G':'6','Y':'7','y':'7','g':'9'}\n",
    "\t    for k,v in d.items():\n",
    "\t        text_string = text_string.replace(k, v)\n",
    "\t    text_string=''.join(filter(lambda x: x.isdigit(),text_string))\n",
    "\texcept:\n",
    "\t\ttext_string = np.nan\n",
    "\treturn text_string\n",
    "\n",
    "def get_df(hr_img_lines,vr_img_lines,document,all_companies, all_stages, all_industries, similarity_threshold):\n",
    "\trows = []\n",
    "\tindices = []\n",
    "\tfor y in range(len(hr_img_lines)-1):\n",
    "\t\tcols=[]\n",
    "\t\tfor x in range(len(vr_img_lines)-1):\n",
    "\t\t\tcell_bbox = [vr_img_lines[x][0], hr_img_lines[y][0], vr_img_lines[x+1][0], hr_img_lines[y+1][0]]\n",
    "\t\t\ttext = text_within(document, cell_bbox)\n",
    "\t\t\tif x==0:\n",
    "\t\t\t\ttext = text.strip()\n",
    "\t\t\t\tif len(text)>0:\n",
    "\t\t\t\t\tcols.append(convert_to_int(text.split()[0]))\n",
    "\t\t\t\t\ttext = text.split()[1:]\n",
    "\n",
    "\t\t\t\t\ttext = ' '.join([each for each in text if not each in ['x','X']])\n",
    "\t\t\t\t\tif len(text)>0:\n",
    "\t\t\t\t\t\tif text[0] in ['0','O']:\n",
    "\t\t\t\t\t\t\ttext = text[1:]\n",
    "\t\t\t\t\ttemp = process.extractOne(text, all_companies, score_cutoff=similarity_threshold)\n",
    "\t\t\t\t\tsimilarity = 0\n",
    "\t\t\t\t\tif temp is not None and len(temp)>0:\n",
    "\t\t\t\t\t\ttext = temp[0]\n",
    "\t\t\t\t\t\tsimilarity = temp[1]\n",
    "\t\t\t\t\tcols.append(str(similarity<similarity_threshold))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tcols.append(np.nan)\n",
    "\t\t\t\t\tcols.append(np.nan)\n",
    "\t\t\t\t\ttext=np.nan\n",
    "\t\t\tif x==1:\n",
    "\t\t\t\ttemp = process.extractOne(text, all_industries, score_cutoff=similarity_threshold)\n",
    "\t\t\t\tsimilarity = 0\n",
    "\t\t\t\tif temp is not None and len(temp)>0:\n",
    "\t\t\t\t\ttext = temp[0]\n",
    "\t\t\t\t\tsimilarity = temp[1]\n",
    "\t\t\t\tcols.append(str(similarity<similarity_threshold))\n",
    "\n",
    "\t\t\tif x==2:\n",
    "\t\t\t\ttext = convert_to_int(text)\n",
    "\t\t\tif x==4:\n",
    "\t\t\t\ttemp = process.extractOne(text, all_stages, score_cutoff=similarity_threshold)\n",
    "\t\t\t\tsimilarity = 0\n",
    "\t\t\t\tif temp is not None and len(temp)>0:\n",
    "\t\t\t\t\ttext = temp[0]\n",
    "\t\t\t\t\tsimilarity = temp[1]\n",
    "\t\t\t\tcols.append(str(similarity<similarity_threshold))\n",
    "\t\t\tif x in [5,6,7]:\n",
    "\t\t\t\ttext = text.replace('.',',')\n",
    "\t\t\t\ttext = [convert_to_int(each) for each in text.split(',')]\n",
    "\t\t\t\ttext = ','.join(text)\n",
    "\t\t\tcols.append(text)\n",
    "\t\trows.append(cols)\n",
    "\tdf = pd.DataFrame(rows)\n",
    "\tdf = df.rename(columns={0:'Index',1:'problem_company',2:'company_name',3:'problem_industry',4:'industry',7:'problem_stage',8:'stage'})\n",
    "\n",
    "\t# indices = list(df['Index'].astype(int))\n",
    "\t# if indices[-1] - indices[0] + 1 == df.shape[0]:\n",
    "\t# \tdf['Index'] = range(indices[0], indices[-1]+1)\n",
    "\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/connect/prashant/Finland/Croatia/Croatia 1-21.PNG\n"
     ]
    }
   ],
   "source": [
    "all_companies = list(pd.read_excel(args['companies_file'],sheet_name=None)[args['country']]['Company Name'])\n",
    "all_stages = list(pd.read_excel(args['stage_options_file'],header=None)[0])\n",
    "all_industries = list(pd.read_excel(args['industry_options_file'])['industry'])\n",
    "similarity_threshold = int(args['similarity_threshold'])\n",
    "img_path = '/home/connect/prashant/Finland/Croatia/Croatia 1-21.PNG'\n",
    "print('Processing '+img_path)\n",
    "\n",
    "document1_path = img_path.split('.')[0]+'_document_td.pickle'\n",
    "if not os.path.exists(document1_path):\n",
    "    document1 = google_hit(img_path, args['vision_credential'], api_type='document_text_detection')\n",
    "    print('api hit')\n",
    "    with open(document1_path,'wb') as f:\n",
    "        pickle.dump(document1,f)\n",
    "else:\n",
    "    with open(document1_path,'rb') as f:\n",
    "        document1 = pickle.load(f)\n",
    "    \n",
    "document2_path = img_path.split('.')[0]+'_td.pickle'\n",
    "if not os.path.exists(document2_path):\n",
    "    document2 = google_hit(img_path, args['vision_credential'], api_type='text_detection')\n",
    "    print('api hit')\n",
    "    with open(document2_path,'wb') as f:\n",
    "        pickle.dump(document2,f)\n",
    "else:\n",
    "    with open(document2_path,'rb') as f:\n",
    "        document2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(img_path)\n",
    "H,W = img.shape[:2] \n",
    "\n",
    "im = get_bin_image(img.copy(), th=220)\n",
    "hr_hist = white_percentage(im, mode='horizontal')\n",
    "hr_img_lines = [(y,hr_hist[y]) for y in range(H) if hr_hist[y]<=5]\n",
    "hr_img_lines = get_band_lines(hr_img_lines, min_band_sep=5, ignore_rate=5, ignore_rate_step=0.1, which='mid')\n",
    "hr_img_lines[0] = [0,0]\n",
    "hr_img_lines[-1] = [H-1,0]\n",
    "\n",
    "vr_hist = white_percentage(im, mode='vertical')\n",
    "vr_img_lines = [(x,vr_hist[x]) for x in range(W) if vr_hist[x]<=5]\n",
    "vr_img_lines = get_band_lines(vr_img_lines, min_band_sep=5, ignore_rate=5, ignore_rate_step=0.1, which='mid')\n",
    "vr_img_lines[0] = [0,0]\n",
    "vr_img_lines[-1] = [W-1,0]\n",
    "# print(len(vr_img_lines),len(hr_img_lines))\n",
    "\n",
    "\n",
    "df1 = get_df(hr_img_lines, vr_img_lines, document1, all_companies, all_stages, all_industries, similarity_threshold)\n",
    "df2 = get_df(hr_img_lines, vr_img_lines, document2, all_companies, all_stages, all_industries, similarity_threshold)\n",
    "\n",
    "df1 = df1.replace('',np.nan)\n",
    "df1.fillna(df2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.title('original image',size=40)\n",
    "plt.imshow(img)\n",
    "for i in hr_img_lines:\n",
    "    cv2.line(img,(0,i[0]),(W,i[0]),(0,255,0),2)\n",
    "    \n",
    "for i in vr_img_lines:\n",
    "    cv2.line(img,(i[0],0),(i[0],H),(0,0,255),2)\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.title('image after tabular cells detection',size=40)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### archives"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from dateutil.parser import parse\n",
    "# from datetime import datetime\n",
    "parse('300-Aug-2000', fuzzy=True).strftime(\"%d-%b-%Y\")\n",
    "\n",
    "all_months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "def correct_Date(s):\n",
    "    month = process.extractOne(re.search('[a-zA-Z]+',s).group(0), all_months)\n",
    "    all_days = ['0'+str(i)  if len(str(i))==1 else str(i) for i in range(1,32)]\n",
    "    day = process.extractOne(re.findall(r'[0-9]+',text)[0], all_days)\n",
    "    year = process.extractOne(re.findall(r'[0-9]+',text)[1], range(2000,2025))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
